Welcome to FinEval! ! !
==============================================

This paper introduces FinEval, an evaluation benchmark specially designed for the Chinese financial sector. FinEval is a series of high-quality multiple-choice questions covering four topics: finance, economics, accounting and professionalism. It includes 4738 questions with 34 topics To ensure a comprehensive evaluation of model performance, FinEval employs various methods, including zero sample, few sample, answer only (AO, answer answer only) and chain of thought (CoT, chain of thought) The state-of-the-art Chinese and English large language models are evaluated on FinEval, and the results show that only GPT-4 achieves 70% accuracy in different prompt settings, which shows that large language models have great growth potential in the financial field Overall, this study provides a strong evaluation benchmark for future large-scale models, while its developmental constraints provide valuable tools.

You can check out our dataset example in AdvancedGuides_ , or check out our **paper (link)** for more details.


.. _GetStarted:
.. toctree::
   :maxdepth: 1
   :caption: Get Started

   get_started/install.md
   get_started/dataset_pre.md
   get_started/quick_start.md

.. _UserGuides:
.. toctree::
   :maxdepth: 1
   :caption: User Guides

   user_guide/how_to_run.md
   user_guide/config.md
   user_guide/api_model.md
   user_guide/custom_model.md
   user_guide/prompt_viewer.md

.. _Prompt:
.. toctree::
   :maxdepth: 1
   :caption: Prompt

   prompt/overview.md
   prompt/zero_shot.md
   prompt/few_shot.md
   prompt/cot.md

.. _AdvancedGuides:
.. toctree::
   :maxdepth: 1
   :caption: Advanced Guides

   advanced_guides/new_dataset.md
   advanced_guides/new_model.md


.. _Other Notes:
.. toctree::
   :maxdepth: 1
   :caption: Other Notes

   other/how_to_submit.md
   other/Contact_Us.md

Indexes & Tables
==================

* :ref:`genindex`
* :ref:`search`
